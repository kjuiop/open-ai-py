{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vertex AI Gemini API 실습\n",
    "\n",
    "- Python 용 Vertex AI SDK 를 활용하여 Gemini 1.5 Pro 모델과 상호작용 및 다양한 작업 실습\n",
    "\n",
    "- 다양한 입력 유형 (텍스트 프롬프트, 이미지, 비디오) 에서 텍스트를 생성하는 것과 다양한 기능과 구성 옵션을 실험하여 결과를 미세조정\n",
    "\n",
    "<br />\n",
    "\n",
    "### Gemini Pro\n",
    "\n",
    "- 다음을 포함한 복잡한 추론을 위해 설계\n",
    "\n",
    "- 대량의 정보를 분석하고 요약\n",
    "\n",
    "- 정교한 크로스 모달 추출 (텍스트, 코드, 이미지)\n",
    "\n",
    "- 복잡한 코드베이스를 통한 문제 해결\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "### Gemini Flash\n",
    "\n",
    "- 속도와 효율성을 위해 최적화되었으며 다음을 제공\n",
    "\n",
    "- 1초 미만의 응답 시간과 높은 처리량\n",
    "\n",
    "- 다양한 작업에 대해 저렴한 비용으로 높은 품질을 제공\n",
    "\n",
    "- 향상된 멀티모달 기능에는 공간 이해 개선, 새로운 출력 모드(텍스트, 오디오, 이미지), 기본 도구 사용(Google 검색, 코드 실행, 타사 기능)\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "### 목표\n",
    "\n",
    "- Python 용 Vertex AI SDK 를 사용하여 Vertex AI 에서 Gemini API 를 사용\n",
    "\n",
    "- Gemini 1.5 Pro(gemeni-1.5-pro) 모델과 상호 작용\n",
    "\n",
    "- 텍스트 프롬프트에서 텍스트를 생성\n",
    "\n",
    "- 다양한 기능과 구성 옵션\n",
    "\n",
    "- 이미지와 텍스트 프롬프트에서 텍스트 생성\n",
    "\n",
    "- 비디오와 텍스트 프롬프트에서 텍스트 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the environment variable if the user doesn't provide Project ID.\n",
    "import os\n",
    "\n",
    "import vertexai\n",
    "\n",
    "PROJECT_ID = \"{project_ID}\"  # @param {type: \"string\", placeholder: \"[your-project-id]\" isTemplate: true}\n",
    "if not PROJECT_ID or PROJECT_ID == \"{project_ID}\":\n",
    "    PROJECT_ID = str(os.environ.get(\"GOOGLE_CLOUD_PROJECT\"))\n",
    "\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"{region}\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    HarmBlockThreshold,\n",
    "    HarmCategory,\n",
    "    Image,\n",
    "    Part,\n",
    "    SafetySetting,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Gemini 1.5 Pro model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GenerativeModel(\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text from text prompts\n",
    "\n",
    "- Send a text prompt to the model using the generate_content method. The generate_content method can handle a wide variety of use cases, including multi-turn chat and multimodal input, depending on what the underlying model supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Why is the sky blue?\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming\n",
    "\n",
    "- By default, the model returns a response after completing the entire generation process. You can also stream the response as it is being generated, and the model will return chunks of the response as soon as they are generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = model.generate_content(\"Why is the sky blue?\", stream=True)\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try your own prompts\n",
    "\n",
    "- What are the biggest challenges facing the healthcare industry?\n",
    "\n",
    "- What are the latest developments in the automotive industry?\n",
    "\n",
    "- What are the biggest opportunities in retail industry?\n",
    "\n",
    "- (Try your own prompts!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Create a numbered list of 10 items. Each item in the list should be a trend in the tech industry.\n",
    "\n",
    "Each trend should be less than 5 words.\"\"\"  # try your own prompt\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model parameter\n",
    "\n",
    "- Every prompt you send to the model includes parameter values that control how the model generates a response. The model can generate different results for different parameter values. You can experiment with different model parameters to see how the results change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = GenerationConfig(\n",
    "    temperature=0.9,\n",
    "    top_p=1.0,\n",
    "    top_k=32,\n",
    "    candidate_count=1,\n",
    "    max_output_tokens=8192,\n",
    ")\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"Why is the sky blue?\",\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Safety filters\n",
    "\n",
    "- The Gemini API provides safety filters that you can adjust across multiple filter categories to restrict or allow certain types of content. You can use these filters to adjust what's appropriate for your use case. See the [Configure safety filters](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/configure-safety-filters) page for details.\n",
    "\n",
    "- When you make a request to Gemini, the content is analyzed and assigned a safety rating. You can inspect the safety ratings of the generated content by printing out the model responses, as in this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"Why is the sky blue?\")\n",
    "\n",
    "print(f\"Safety ratings:\\n{response.candidates[0].safety_ratings}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use safety_settings to adjust the safety settings for each request you make to the API. This example demonstrates how you set the block threshold to BLOCK_ONLY_HIGH for the dangerous content category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safety_settings = [\n",
    "    SafetySetting(\n",
    "        category=HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold=HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    ),\n",
    "]\n",
    "\n",
    "prompt = \"\"\"\n",
    "    Write a list of 2 disrespectful things that I might say to the universe after stubbing my toe in the dark.\n",
    "\"\"\"\n",
    "\n",
    "response = model.generate_content(\n",
    "    prompt,\n",
    "    safety_settings=safety_settings,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text from multimodal prompt\n",
    "\n",
    "- Gemini 1.5 Pro (gemini-1.5-pro) is a multimodal model that supports multimodal prompts. You can include text, image(s), and video in your prompt requests and get text or code responses.\n",
    "\n",
    "### Define helper functions\n",
    "\n",
    "- Define helper functions to load and display images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import typing\n",
    "import urllib.request\n",
    "\n",
    "import IPython.display\n",
    "from PIL import Image as PIL_Image\n",
    "from PIL import ImageOps as PIL_ImageOps\n",
    "\n",
    "\n",
    "def display_images(\n",
    "    images: typing.Iterable[Image],\n",
    "    max_width: int = 600,\n",
    "    max_height: int = 350,\n",
    ") -> None:\n",
    "    for image in images:\n",
    "        pil_image = typing.cast(PIL_Image.Image, image._pil_image)\n",
    "        if pil_image.mode != \"RGB\":\n",
    "            # RGB is supported by all Jupyter environments (e.g. RGBA is not yet)\n",
    "            pil_image = pil_image.convert(\"RGB\")\n",
    "        image_width, image_height = pil_image.size\n",
    "        if max_width < image_width or max_height < image_height:\n",
    "            # Resize to display a smaller notebook image\n",
    "            pil_image = PIL_ImageOps.contain(pil_image, (max_width, max_height))\n",
    "        IPython.display.display(pil_image)\n",
    "\n",
    "\n",
    "def get_image_bytes_from_url(image_url: str) -> bytes:\n",
    "    with urllib.request.urlopen(image_url) as response:\n",
    "        response = typing.cast(http.client.HTTPResponse, response)\n",
    "        image_bytes = response.read()\n",
    "    return image_bytes\n",
    "\n",
    "\n",
    "def load_image_from_url(image_url: str) -> Image:\n",
    "    image_bytes = get_image_bytes_from_url(image_url)\n",
    "    return Image.from_bytes(image_bytes)\n",
    "\n",
    "\n",
    "def get_url_from_gcs(gcs_uri: str) -> str:\n",
    "    # converts GCS uri to url for image display.\n",
    "    url = \"https://storage.googleapis.com/\" + gcs_uri.replace(\"gs://\", \"\").replace(\n",
    "        \" \", \"%20\"\n",
    "    )\n",
    "    return url\n",
    "\n",
    "\n",
    "def print_multimodal_prompt(contents: list):\n",
    "    \"\"\"\n",
    "    Given contents that would be sent to Gemini,\n",
    "    output the full multimodal prompt for ease of readability.\n",
    "    \"\"\"\n",
    "    for content in contents:\n",
    "        if isinstance(content, Image):\n",
    "            display_images([content])\n",
    "        elif isinstance(content, Part):\n",
    "            url = get_url_from_gcs(content.file_data.file_uri)\n",
    "            IPython.display.display(load_image_from_url(url))\n",
    "        else:\n",
    "            print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate text from a video file\n",
    "\n",
    "- Specify the Cloud Storage URI of the video to include in the prompt. The bucket that stores the file must be in the same Google Cloud project that's sending the request. You must also specify the mime_type field. The supported MIME type for video includes video/mp4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"github-repo/img/gemini/multimodality_usecases_overview/pixel8.mp4\"\n",
    "video_uri = f\"gs://{file_path}\"\n",
    "video_url = f\"https://storage.googleapis.com/{file_path}\"\n",
    "\n",
    "IPython.display.Video(video_url, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the following questions using the video only:\n",
    "What is the profession of the main person?\n",
    "What are the main features of the phone highlighted?\n",
    "Which city was this recorded in?\n",
    "Provide the answer in JSON.\n",
    "\"\"\"\n",
    "\n",
    "video = Part.from_uri(video_uri, mime_type=\"video/mp4\")\n",
    "contents = [prompt, video]\n",
    "\n",
    "response = model.generate_content(contents)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct analysis of publicly available web media\n",
    "\n",
    "- This new feature enables you to directly process publicly available URL resources including images, text, video and audio with Gemini. This feature supports all currently supported modalities and file formats.\n",
    "\n",
    "In this example, you add the file URL of a publicly available image file to the request to identify what's in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Extract the objects in the given image and output them in a list in alphabetical order.\n",
    "\"\"\"\n",
    "\n",
    "image_file = Part.from_uri(\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/image/office-desk.jpeg\",\n",
    "    \"image/jpeg\",\n",
    ")\n",
    "\n",
    "response = model.generate_content([image_file, prompt])\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how to add the file URL of a publicly available video file to the request, and use the controlled generation capability to constraint the model output to a structured format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schema = {\n",
    "    \"type\": \"ARRAY\",\n",
    "    \"items\": {\n",
    "        \"type\": \"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"timecode\": {\n",
    "                \"type\": \"STRING\",\n",
    "            },\n",
    "            \"chapter_summary\": {\n",
    "                \"type\": \"STRING\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"timecode\", \"chapter_summary\"],\n",
    "    },\n",
    "}\n",
    "\n",
    "prompt = \"\"\"\n",
    "Chapterize this video content by grouping the video content into chapters and providing a brief summary for each chapter. \n",
    "Please only capture key events and highlights. If you are not sure about any info, please do not make it up. \n",
    "\"\"\"\n",
    "\n",
    "video_file = Part.from_uri(\n",
    "    \"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/rio_de_janeiro_beyond_the_map_rio.mp4\",\n",
    "    \"video/mp4\",\n",
    ")\n",
    "\n",
    "response = model.generate_content(\n",
    "    contents=[video_file, prompt],\n",
    "    generation_config=GenerationConfig(\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema,\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
