{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 이란?\n",
    "\n",
    "- 대규모 언어 모델(Large Language Models)\n",
    "\n",
    "- LLM 은 딥 러닝의 하위 집합, LLM 과 생성 AI 는 둘 다 딥러닝의 일부 \n",
    "\n",
    "- 생성형 AI 는 텍스트, 이미지, 오디오, 합성 데이터 등 새로운 콘텐츠를 생산할 수 있는 인공지능\n",
    "\n",
    "- LLLM 은 사전 훈련된 다음 특정 목적에 맞게 미세 조정할 수 있는 대규모 범용 언어 모델을 의미\n",
    "\n",
    "- LLM 은 텍스트, 분류, 질문과 답변, 문서 요약, 텍스트 생성과 같은 공통 언어문제를 해결하기 위한 목적으로 훈련됨 \n",
    "\n",
    "<br />\n",
    "\n",
    "### LLM 의 특징 (Large)\n",
    "\n",
    "1. 훈련 데이터세트의 크기가 큼 (페타바이트 규모에 달하기도 함)\n",
    "\n",
    "2. 많은 수의 매개 변수(하이퍼파라미터)를 나타냄 (수십억개)\n",
    "\n",
    "- 매개변수란 기계가 모델 훈련을 통해 학습한 기억과 지식을 의미\n",
    "\n",
    "- 매개변수는 텍스트 예측과 같은 문제 해결에서 모델의 기술을 정의\n",
    "\n",
    "<br />\n",
    "\n",
    "### LLM 의 특징 (General)\n",
    "\n",
    "- 모델의 일반적인 목적은 범용적인 문제를 해결하기 위함\n",
    "\n",
    "- 자원은 한정적이다. 특정 조직만이 엄청나게 큰 데이터세트와 매개변수를 사용하여 LLM 을 훈련시킬 수 있는 능력을 갖추고 있다.\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "### 사전 훈련 및 미세조정\n",
    "\n",
    "- 큰 데이터세트를 사용하여 일반적인 목적을 위해 대형 언어 모델을 사전 훈련한 훨씬 더 작은 데이터세트를 사용하여 특정 목표에 맞게 미세조정하는 것을 의미\n",
    "\n",
    "<br />\n",
    "\n",
    "### LLM 사용사례\n",
    "\n",
    "- 단일 모델을 다양한 작업에 사용할 수 있다.\n",
    "\n",
    "- 특정 문제를 해결하기 위해 맞춤화할 때 대규모 언어 모델에는 최소한의 현장 교육 데이터가 필요하다.\n",
    "\n",
    "- LLM 은 퓨샷 (최소한의 데이터로 모델을 훈련시키는 것), 제로샷 (이전 훈련에서 명시적으로 가르쳐주지 않는 것들을 모델이 인식) 에서도 사용될 수 있다.\n",
    "\n",
    "- 더 많은 데이터와 매개변수를 추가하면 대규모 언어 모델의 성능이 지속적으로 향상된다.\n",
    "\n",
    "- LLM 은 변환기 모델을 기반으로 함\n",
    "\n",
    "- 변환기 모델은 인코더 (입력 시퀀스를 인코딩) 와 디코더 (관련 작업에 대한 표현을 디코딩하는 방법을 학습) 로 구성됨\n",
    "\n",
    "- LaMDA 와 같은 모델은 인터넷을 통해 여러 소스에서 학습하며 입력 여부에 관계 없이 질문만으로 사용할 수 있는 기초 언어 모델을 구축함\n",
    "\n",
    "- 즉, 프롬프트 자체에 대해 질문으로 구성할 수 있음\n",
    "\n",
    "<br />\n",
    "\n",
    "### LLM 개발의 장점\n",
    "\n",
    "- LLM 개발은 전문가가 될 필요가 없음, 훈련 예제가 필요없고, 모델을 훈련할 필요도 없음\n",
    "\n",
    "- 개발자가 해야할 일은 유익한 프롬프트를 만드는 프롬프트 디자인에 대해 생각하는 것\n",
    "\n",
    "- 이는 자연어 처리(NLP) 에서 매우 중요한 부분\n",
    "\n",
    "- 프롬프트 디자인은 시스템이 수행하도록 요청받는 특정 작업에 맞게 조정된 프롬프트를 만드는 프로세스\n",
    "\n",
    "- 프롬프트 엔지니어링은 성능을 향상시키도록 설꼐된 프롬프트를 생성하는 프로세스\n",
    "\n",
    "- 도메인별 지식, 원하는 결과의 예를 제공하거나, 특정 시스템에 효과적인 것으로 알려진 키워드를 사용\n",
    "\n",
    "- 이러한 프롬프트 엔지니어링은 높은 수준의 정확성이나 성능이 요구되는 시스템에 필요함\n",
    "\n",
    "- 일반언어모델, 명령 조정, 대화 조정의 세 가지 종류가 있음\n",
    "\n",
    "- 일반언어모델은 훈련 데이터의 언어를 기반으로 다음 단어를 예측함\n",
    "\n",
    "- 지침조정 모델은 입력에 제공된 지침에 대한 응답을 예측하도록 학습됨 \n",
    "\n",
    "- 대화조정 모델은 요청이 일반적으로 채팅 봇에 대한 질문으로 구성되는 조정된 명령의 특별한 경우\n",
    "\n",
    "- 대화조정은 더 긴 대화의 맥락에서 이루어질 것으로 예상되며 일반적으로 자연스럽고 질문과 같은 표현에서 더 잘 작동됨\n",
    "\n",
    "- 사고연쇄추론은 모델이 답의 이유를 설명하는 텍스트를 처음 출력할 때 올바른 답을 더 잘 얻는다는 관찰\n",
    "\n",
    "- Vertex AI 는 작업별 기반 모델을 제공\n",
    "\n",
    "- 자체 데이터세트를 가져와 LLM 의 모든 가중치를 조정하여 모델을 재교육하는 미세조정을 통해 모델을 추가로 조정할 수 있음\n",
    "\n",
    "- 이를 위해서는 대규모 교육 작업과 자체적으로 미세 조정된 모델을 호스팅해야 함\n",
    "\n",
    "- 그러나 미세 조정은 비용이 많이 들고, 현실적이지 않은 경우가 있음\n",
    "\n",
    "- 매개변수 효율적인 조정 방법(PETM)은 모델을 복제하지 않고 사용자 정의 데이터에 대해 대규모 언어 모델을 조정하는 방법\n",
    "\n",
    "- 기본 모델은 변경되지 않고 추론 시 교체할 수 있는 소수의 추가 레이어가 조정됨\n",
    "\n",
    "<br />\n",
    "\n",
    "### LLM 을 최대한 활용하는 방법\n",
    "\n",
    "1. Vertex AI Studio\n",
    "\n",
    "- Google Cloud 의 애플리케이션에서 활용할 수 있는 생성 AI 모델을 빠르게 탐색하고 맞춤설정할 수 있음\n",
    "\n",
    "- 쉽게 시작할 수 있는 다양한 도구와 리소스를 제공하여 개발자가 생성 AI 모델을 만들고 배포하는데 도움을 줌\n",
    "\n",
    "- 사전학습된 라이브러리, 모델 미세 조정을 위한 도구, 모델을 프로덕션에 배포하기 위한 도구, 커뮤니티 포럼 \n",
    "\n",
    "- Vertex AI 는 챗봇, 디지털 어시스턴트, 커스텀 검색 엔진, 기술 자료, 교육 애플리케이션을 직접 만드는데 도움을 줌 \n",
    "\n",
    "- Gemini 는 다중 AI 모델, 고급 아키텍처로 적응력과 확장성이 뛰어나다. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
