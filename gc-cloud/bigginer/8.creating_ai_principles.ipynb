{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google AI principle\n",
    "\n",
    "- AI 원칙을 적용하여 연구 및 제품 개발 프로세스를 적극적으로 관리하고 사업 결정을 안내\n",
    "\n",
    "- Google 은 AI 원칙에 따라 AI 윤리 헌장을 설계\n",
    "\n",
    "- 팀을 구성할 때 Google 은 다양한 기술, 배경, 인구 통계를 대표하는 개인을 선정\n",
    "\n",
    "- 기술적 관점에서는 사용자 연구, 법률, 공공 정책, 개인정보 보호, 온라인 안전, 지속 가능성, 비영리 단체 분야의 배경을 가진 그룹의 인원으로 구성\n",
    "\n",
    "- AI, 인권, 시민권 분야의 전문가와 핵심 작업 그룹에 속하지 않은 제품 전문가로부터 의견을 구함\n",
    "\n",
    "- 실무에 참여하지 않는 사람들에게도 의견을 구함\n",
    "\n",
    "<br />\n",
    "\n",
    "## Ethical issues spotting\n",
    "\n",
    "- AI 거버넌스의 핵심은 강력한 문제 발견(윤리적 문제의 가능성을 인식) 관행\n",
    "\n",
    "- AI 원칙을 만드는데 체크리스트로는 실현이 불가능했다.\n",
    "\n",
    "- 문제의 발견의 목표는 더욱 민감하게 윤리적 문제와 위험을 빠르고 정확하게 식별하고 분류할 수 있는 능력을 키우는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical aims of google ai principles\n",
    "\n",
    "1. 사회적으로 유익해야 하며, 건강한 사회 시스템과 기관을 지원해야 한다.\n",
    "\n",
    "<br />\n",
    "\n",
    "2. 불공정한 편견을 만들거나 강화하지 않는다.\n",
    "\n",
    "- 문화의 다양성을 반영하기 위해 AI 훈련이 필요하다.\n",
    "\n",
    "- 훈련 데이터는 제한된 데이터 세트가 표현하는 대로가 아닌, 사회를 있는 그대로 표현할 수 있어야 하므로 확장된 데이터 세트가 필요하다.\n",
    "\n",
    "- ML 수명주기의 어느 지점에서든 불공정성이 시스템에 유입될 수 있다는 점을 인식해야 한다.\n",
    "\n",
    "- 데이터를 수집하고 준비하는 방법, 모델을 훈련하고 평가하는 방법, 모델을 통합하고 사용하는 방법에 관한 것\n",
    "\n",
    "- 이 흐름의 각 단계에서 개발자는 책임있는 AI 에 대한 다양한 질문과 고려사항에 직면하게 됨\n",
    "\n",
    "<br />\n",
    "\n",
    "### 각 단계에서 필요한 질문들\n",
    "\n",
    "- 이 모델은 어떤 문제를 해결할 것인가?\n",
    "\n",
    "- 의도된 사용자는 누구인가?\n",
    "\n",
    "- 어떤 다른 그룹이 영향을 받을 수 있을까?\n",
    "\n",
    "- 오늘날 눈에 띄지 않는 집다는 무엇인가?\n",
    "\n",
    "- 훈련 데이터는 어떻게 수집, 샘플링되고 레이블이 지정되었는가\n",
    "\n",
    "- 훈련 데이터는 왜곡되어 있는가\n",
    "\n",
    "- 이 모델은 어떻게 테스트하고 검증되었는가\n",
    "\n",
    "- 모델이 예상대로 동작하고 있는가\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "3. 안전을 위해 제작 및 테스트는 신체적 무결성과 전반적인 건강 모두의 안전을 증진하는 것을 목표로 함\n",
    "\n",
    "- 사람과 지역 사회, 장소, 시스템, 재산, 인프라를 공격이나 중단으로부터 안전하게 보호하는 것을 말함\n",
    "\n",
    "- 안전에 중요한 애플리케이션에 대한 효과적인 감독 및 테스트가 이루어지도록 보장하는 것을 목표로 함\n",
    "\n",
    "- AI 시스템의 행동을 제어하는 것이 중요하며, 기계 지능에 대한 의존에는 한계가 있다.\n",
    "\n",
    "<br />\n",
    "\n",
    "4. 국민에 대한 책임을 져야 하며 국민의 권리와 독립성을 존중하는 것을 목표로 해야 한다.\n",
    "\n",
    "- 권력 불평등을 제한하고 사람들이 AI 상호작용에서 제외할 수 있는 능력이 부족한 상황을 제한하는 것을 의미\n",
    "\n",
    "- 사용자의 정보에 기반한 동의를 촉진하는 것을 목표로 하며, 오용, 부당한 사용 또는 오작동을 보고하고 시정할 수 있는 방안 마련\n",
    "\n",
    "<br />\n",
    "\n",
    "5. AI 원칙에는 개인정보 보호 설계 원칙이 통합되어 있으며, 그 목표는 개인과 그룹 모두의 개인 정보와 안전을 보호하는 것\n",
    "\n",
    "- 강력한 보안을 통해 개인 식별 정보와 민감한 데이터가 특별한 주의를 기울여 처리되도록 함\n",
    "\n",
    "- 이 원칙의 목적은 사용자가 데이터 처리 방법에 대해 명확한 기대를 갖도록 하는 것입니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "6. 과학적 우수성에 대한 높은 기준을 유지한다는 원칙은 AI 에 대한 지식 수준을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "- 과학적으로 엄격한 접근 방식을 따르고 기능 주장이 과학적으로 신뢰할 수 있는지 확인하는 것을 의미합니다.\n",
    "\n",
    "- 이 원칙은 개방적인 탐구, 지적 엄격성, 정직성, 협력에 대한 헌신을 통해 달성하는 것을 목표로 합니다.\n",
    "\n",
    "<br />\n",
    "\n",
    "7. AI 원칙의 마지막 원칙은 AI 응용 프로그램에 대한 목표가 이러한 원칙에 부합하는 용도로 사용되도록 하며, 사회에 미치는 Google 의 독특한 영향에 대한 책임을 추구합니다.\n",
    "\n",
    "- 잠재적으로 해롭거나 남용적인 응용 프로그램을 제한하는 것을 목표로 합니다.\n",
    "\n",
    "- 기술 솔루션이 유해한 용도와 얼마나 밀접하게 관련되어 있는지, 적응할 수 있는지 확인합니다.\n",
    "\n",
    "\n",
    "<br />\n",
    "\n",
    "### 구글이 추구하지 않을 4가지 AI 응용 분야\n",
    "\n",
    "1. 전반적인 피해를 일으킬 가능성이 있는 AI 애플리케이션\n",
    "\n",
    "2. 주된 목적이 무기 또는 기타 기술인 경우\n",
    "\n",
    "3. 사람에게 부상을 입히는 행위\n",
    "\n",
    "4. 국제적으로 인정된 규범을 위반하는 감시 그리고 그 목적이 국제법과 인권에 위배되는 감시\n",
    "\n",
    "<br />\n",
    "\n",
    "- AI 원칙을 현실화하기 위해 구글은 새로운 프로젝트, 제품 및 거래에서 발생하는 다각적인 윤리적 문제를 평가하는 거버넌스 구조를 갖춘 공식적인 검토 프로세스를 수립\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
